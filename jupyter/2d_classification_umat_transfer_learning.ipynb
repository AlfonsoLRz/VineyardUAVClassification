{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import config\n",
    "from cnn_builder import *\n",
    "from config import *\n",
    "from dataset_functions import *\n",
    "import gc\n",
    "from hypercube_set import HypercubeSet\n",
    "from hypercube_loader import *\n",
    "import numpy as np\n",
    "import papers\n",
    "import paths\n",
    "import rendering\n",
    "import training_history\n",
    "\n",
    "import os\n",
    "os.environ[\"PATH\"] += os.pathsep + 'C:/Program Files/Graphviz/bin/'\n",
    "os.chdir(os.getcwd().split(\"jupyter\")[0])\n",
    "\n",
    "inf = 2e32\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "inf = 2e32\n",
    "sampling_strategy = 'not minority'\n",
    "\n",
    "network_type = 'allopezr_2d'\n",
    "read_json_config(paths.config_file, network_type=network_type)\n",
    "network_name = get_name(network_type)\n",
    "\n",
    "read_json_config(paths.config_file, network_type=network_type)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "config.batch_size = 256 # Indian pines"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'__header__': b'MATLAB 5.0 MAT-file, Platform: GLNXA64, Created on: Fri May 20 18:47:44 2011', '__version__': '1.0', '__globals__': [], 'indian_pines_corrected': array([[[3172, 4142, 4506, ..., 1057, 1020, 1020],\n",
      "        [2580, 4266, 4502, ..., 1064, 1029, 1020],\n",
      "        [3687, 4266, 4421, ..., 1061, 1030, 1016],\n",
      "        ...,\n",
      "        [2570, 3890, 4320, ..., 1042, 1021, 1015],\n",
      "        [3170, 4130, 4320, ..., 1054, 1024, 1020],\n",
      "        [3172, 3890, 4316, ..., 1043, 1034, 1016]],\n",
      "\n",
      "       [[2576, 4388, 4334, ..., 1047, 1030, 1006],\n",
      "        [2747, 4264, 4592, ..., 1055, 1039, 1015],\n",
      "        [2750, 4268, 4423, ..., 1047, 1026, 1015],\n",
      "        ...,\n",
      "        [3859, 4512, 4605, ..., 1056, 1035, 1015],\n",
      "        [3686, 4264, 4690, ..., 1051, 1012, 1020],\n",
      "        [2744, 4268, 4597, ..., 1047, 1019, 1016]],\n",
      "\n",
      "       [[2744, 4146, 4416, ..., 1055, 1029, 1025],\n",
      "        [2576, 4389, 4416, ..., 1051, 1021, 1011],\n",
      "        [2744, 4273, 4420, ..., 1068, 1033, 1010],\n",
      "        ...,\n",
      "        [2570, 4266, 4509, ..., 1051, 1025, 1010],\n",
      "        [2576, 4262, 4496, ..., 1047, 1029, 1020],\n",
      "        [2742, 4142, 4230, ..., 1042, 1025, 1011]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[3324, 3728, 4002, ..., 1003, 1004, 1004],\n",
      "        [2983, 3604, 3829, ..., 1011, 1013, 1008],\n",
      "        [2988, 3612, 3913, ..., 1012, 1001, 1004],\n",
      "        ...,\n",
      "        [2564, 4115, 4103, ..., 1003, 1005, 1013],\n",
      "        [2730, 4111, 4103, ..., 1015, 1013, 1004],\n",
      "        [3156, 3991, 4103, ..., 1017, 1014, 1000]],\n",
      "\n",
      "       [[3161, 3731, 3834, ..., 1002, 1000, 1000],\n",
      "        [2727, 3742, 4011, ...,  999,  991, 1003],\n",
      "        [2988, 4114, 4011, ..., 1006, 1008, 1013],\n",
      "        ...,\n",
      "        [3156, 3858, 4016, ..., 1011, 1004, 1003],\n",
      "        [3159, 3858, 4100, ..., 1016, 1000, 1000],\n",
      "        [2561, 3866, 4003, ..., 1008, 1008, 1000]],\n",
      "\n",
      "       [[2979, 3728, 3732, ..., 1006, 1004, 1000],\n",
      "        [2977, 3728, 3741, ..., 1007, 1009,  990],\n",
      "        [2814, 3728, 3914, ...,  999, 1009, 1003],\n",
      "        ...,\n",
      "        [3153, 3864, 4282, ..., 1003, 1008, 1000],\n",
      "        [3155, 4104, 4106, ..., 1011, 1005, 1003],\n",
      "        [3323, 3860, 4197, ..., 1007, 1004, 1000]]], dtype=uint16)}\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0: 46\n",
      "Class 1: 1428\n",
      "Class 2: 830\n",
      "Class 3: 237\n",
      "Class 4: 483\n",
      "Class 5: 730\n",
      "Class 6: 28\n",
      "Class 7: 478\n",
      "Class 8: 20\n",
      "Class 9: 972\n",
      "Class 10: 2455\n",
      "Class 11: 593\n",
      "Class 12: 205\n",
      "Class 13: 1265\n",
      "Class 14: 386\n",
      "Class 15: 93\n",
      "Class 16: 10776\n",
      "Min: 955.0, Max: 9604.0, Size: (145, 145, 200)\n"
     ]
    }
   ],
   "source": [
    "hc_set = HypercubeSet(hc_array=[load_indian_pines_umat(plot_hc=False, plot_mask=True)])\n",
    "hc_set.print_metadata()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    }
   ],
   "source": [
    "ground_label = hc_set.get_most_frequent_label()\n",
    "print(ground_label)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "hc_set.obtain_ground_labels(ground_label=ground_label)\n",
    "hc_set.obtain_train_indices(test_percentage=config.test_split, patch_size=config.patch_size, patch_overlapping=config.patch_overlapping)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21025, 200)\n",
      "(21025,)\n",
      "on 0: (14717, 200)                                                                                                      \n",
      "|████████████████████████████████████████| 2/2 [100%] in 1.8s (1.14/s)                                                  \n"
     ]
    }
   ],
   "source": [
    "hc_set.standardize(num_features=config.num_target_features, selection_method=LayerSelectionMethod.FACTOR_ANALYSIS)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "num_classes = hc_set.get_num_classes() - 1\n",
    "img_shape = (config.patch_size, config.patch_size, config.num_target_features)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|████████████████████████████████████████| 6308/6308 [100%] in 0.0s (261764.45/s)                                       \n"
     ]
    }
   ],
   "source": [
    "X_test, y_test = hc_set.split_test(patch_size=config.patch_size)\n",
    "y_test = reduce_labels_center(y_test)\n",
    "X_test, y_test = remove_labels(X_test, y_test, [ground_label])\n",
    "(X_test, y_test), _, _ = balance_classes(X_test, y_test, reduce=True, clustering=False, strategy=sampling_strategy)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 23, 23, 30)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 529, 30)      0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " lambda (Lambda)                (None, 529, 30)      0           ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " spatial_attention (SpatialAtte  (None, 529, 30)     1058        ['lambda[0][0]']                 \n",
      " ntion)                                                                                           \n",
      "                                                                                                  \n",
      " reshape_1 (Reshape)            (None, 23, 23, 30)   0           ['spatial_attention[0][0]']      \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 23, 23, 60)   0           ['input_1[0][0]',                \n",
      "                                                                  'reshape_1[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 23, 23, 32)   1952        ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 23, 23, 32)   1952        ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 12, 12, 60)   0           ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 12, 12, 32)   9248        ['conv2d[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 12, 12, 32)   25632       ['conv2d_2[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 12, 12, 32)   1952        ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 12, 12, 96)   0           ['conv2d_1[0][0]',               \n",
      "                                                                  'conv2d_3[0][0]',               \n",
      "                                                                  'conv2d_4[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 12, 12, 96)  384         ['concatenate_1[0][0]']          \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " leaky_re_lu (LeakyReLU)        (None, 12, 12, 96)   0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 12, 12, 96)   0           ['leaky_re_lu[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 6, 6, 96)     9312        ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 6, 6, 96)     83040       ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 6, 6, 96)     230496      ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 6, 6, 96)    0           ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 6, 6, 384)    0           ['conv2d_5[0][0]',               \n",
      "                                                                  'conv2d_6[0][0]',               \n",
      "                                                                  'conv2d_7[0][0]',               \n",
      "                                                                  'max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 6, 6, 384)   1536        ['concatenate_2[0][0]']          \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " leaky_re_lu_1 (LeakyReLU)      (None, 6, 6, 384)    0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 13824)        0           ['leaky_re_lu_1[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 13824)        0           ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 16)           221200      ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 587,762\n",
      "Trainable params: 586,802\n",
      "Non-trainable params: 960\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.engine.functional.Functional at 0x2836efc7fa0>"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_name = get_name(network_type)\n",
    "network_file = os.path.join(paths.result_folder + 'network/', network_name + \"_0.h5\")\n",
    "model = keras.models.load_model(network_file,\n",
    "                            custom_objects={'SpatialAttention': papers.aspn.SpatialAttention,\n",
    "                                            'SecondOrderPooling': papers.aspn.SecondOrderPooling})\n",
    "model.trainable = True\n",
    "non_trainable_layers = [2, 3, 6, 7, 9, 10, 11, 16, 17, 18]\n",
    "network_name = network_name + '_indian_pines'\n",
    "\n",
    "x = Dense(num_classes)(model.layers[-2].output)\n",
    "model = Model(inputs=model.input, outputs=x)\n",
    "compile_network(model, network_type, network_name, num_classes, show_summary=True, render_image=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "history = training_history.TrainingHistory(accuracy_name='sparse_categorical_accuracy')\n",
    "callbacks, time_callback = get_callback_list(model_name=network_name, test_id=100)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|████████████████████████████████████████| 14717/14717 [100%] in 0.1s (249072.88/s)                                     \n",
      "Training for 100 epochs with batch size of 512...\n",
      "Epoch 1/100\n",
      " 5/52 [=>............................] - ETA: 1s - loss: 7.7150 - sparse_categorical_accuracy: 0.2109WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0278s vs `on_train_batch_end` time: 0.0323s). Check your callbacks.\n",
      "51/52 [============================>.] - ETA: 0s - loss: 4.2975 - sparse_categorical_accuracy: 0.4968\n",
      "Epoch 1: val_loss improved from inf to 2.11986, saving model to results/network\\allopezr_2d_23x22_16_indian_pines_100.h5\n",
      "52/52 [==============================] - 5s 64ms/step - loss: 4.2896 - sparse_categorical_accuracy: 0.4972 - val_loss: 2.1199 - val_sparse_categorical_accuracy: 0.6533\n",
      "Epoch 2/100\n",
      "52/52 [==============================] - ETA: 0s - loss: 2.4654 - sparse_categorical_accuracy: 0.5622\n",
      "Epoch 2: val_loss did not improve from 2.11986\n",
      "52/52 [==============================] - 2s 48ms/step - loss: 2.4654 - sparse_categorical_accuracy: 0.5622 - val_loss: 2.3966 - val_sparse_categorical_accuracy: 0.6045\n",
      "Epoch 3/100\n",
      "51/52 [============================>.] - ETA: 0s - loss: 2.5729 - sparse_categorical_accuracy: 0.4920\n",
      "Epoch 3: val_loss did not improve from 2.11986\n",
      "52/52 [==============================] - 2s 42ms/step - loss: 2.5729 - sparse_categorical_accuracy: 0.4918 - val_loss: 2.5378 - val_sparse_categorical_accuracy: 0.5795\n",
      "Epoch 4/100\n",
      "51/52 [============================>.] - ETA: 0s - loss: 2.5990 - sparse_categorical_accuracy: 0.4603\n",
      "Epoch 4: val_loss did not improve from 2.11986\n",
      "52/52 [==============================] - 2s 43ms/step - loss: 2.5989 - sparse_categorical_accuracy: 0.4603 - val_loss: 2.5023 - val_sparse_categorical_accuracy: 0.5510\n",
      "Epoch 5/100\n",
      "51/52 [============================>.] - ETA: 0s - loss: 2.5327 - sparse_categorical_accuracy: 0.4649\n",
      "Epoch 5: val_loss did not improve from 2.11986\n",
      "52/52 [==============================] - 2s 41ms/step - loss: 2.5325 - sparse_categorical_accuracy: 0.4650 - val_loss: 2.4071 - val_sparse_categorical_accuracy: 0.5578\n",
      "Epoch 6/100\n",
      "51/52 [============================>.] - ETA: 0s - loss: 2.4725 - sparse_categorical_accuracy: 0.4789\n",
      "Epoch 6: val_loss did not improve from 2.11986\n",
      "52/52 [==============================] - 2s 44ms/step - loss: 2.4727 - sparse_categorical_accuracy: 0.4786 - val_loss: 2.3795 - val_sparse_categorical_accuracy: 0.5791\n",
      "Epoch 7/100\n",
      "51/52 [============================>.] - ETA: 0s - loss: 2.4029 - sparse_categorical_accuracy: 0.5182\n",
      "Epoch 7: val_loss did not improve from 2.11986\n",
      "52/52 [==============================] - 2s 41ms/step - loss: 2.4032 - sparse_categorical_accuracy: 0.5183 - val_loss: 2.3338 - val_sparse_categorical_accuracy: 0.5860\n",
      "Epoch 8/100\n",
      "51/52 [============================>.] - ETA: 0s - loss: 2.3617 - sparse_categorical_accuracy: 0.5138\n",
      "Epoch 8: val_loss did not improve from 2.11986\n",
      "52/52 [==============================] - 2s 43ms/step - loss: 2.3612 - sparse_categorical_accuracy: 0.5139 - val_loss: 2.2453 - val_sparse_categorical_accuracy: 0.5901\n",
      "Epoch 9/100\n",
      "51/52 [============================>.] - ETA: 0s - loss: 2.3348 - sparse_categorical_accuracy: 0.5290\n",
      "Epoch 9: val_loss did not improve from 2.11986\n",
      "52/52 [==============================] - 2s 41ms/step - loss: 2.3345 - sparse_categorical_accuracy: 0.5293 - val_loss: 2.2405 - val_sparse_categorical_accuracy: 0.6035\n",
      "Epoch 10/100\n",
      "51/52 [============================>.] - ETA: 0s - loss: 2.2439 - sparse_categorical_accuracy: 0.5484\n",
      "Epoch 10: val_loss did not improve from 2.11986\n",
      "52/52 [==============================] - 2s 44ms/step - loss: 2.2439 - sparse_categorical_accuracy: 0.5480 - val_loss: 2.1330 - val_sparse_categorical_accuracy: 0.6214\n",
      "Epoch 11/100\n",
      "51/52 [============================>.] - ETA: 0s - loss: 2.2150 - sparse_categorical_accuracy: 0.5555\n",
      "Epoch 11: val_loss improved from 2.11986 to 2.10538, saving model to results/network\\allopezr_2d_23x22_16_indian_pines_100.h5\n",
      "52/52 [==============================] - 2s 46ms/step - loss: 2.2153 - sparse_categorical_accuracy: 0.5556 - val_loss: 2.1054 - val_sparse_categorical_accuracy: 0.6317\n",
      "Epoch 12/100\n",
      "51/52 [============================>.] - ETA: 0s - loss: 2.1804 - sparse_categorical_accuracy: 0.5802\n",
      "Epoch 12: val_loss did not improve from 2.10538\n",
      "52/52 [==============================] - 2s 41ms/step - loss: 2.1806 - sparse_categorical_accuracy: 0.5803 - val_loss: 2.1235 - val_sparse_categorical_accuracy: 0.6447\n",
      "Epoch 13/100\n",
      "51/52 [============================>.] - ETA: 0s - loss: 2.2000 - sparse_categorical_accuracy: 0.5661\n",
      "Epoch 13: val_loss did not improve from 2.10538\n",
      "52/52 [==============================] - 2s 42ms/step - loss: 2.1997 - sparse_categorical_accuracy: 0.5660 - val_loss: 2.1596 - val_sparse_categorical_accuracy: 0.6025\n",
      "Epoch 14/100\n",
      "51/52 [============================>.] - ETA: 0s - loss: 2.1939 - sparse_categorical_accuracy: 0.5506\n",
      "Epoch 14: val_loss improved from 2.10538 to 2.10443, saving model to results/network\\allopezr_2d_23x22_16_indian_pines_100.h5\n",
      "52/52 [==============================] - 2s 42ms/step - loss: 2.1941 - sparse_categorical_accuracy: 0.5502 - val_loss: 2.1044 - val_sparse_categorical_accuracy: 0.6038\n",
      "Epoch 15/100\n",
      "51/52 [============================>.] - ETA: 0s - loss: 2.1515 - sparse_categorical_accuracy: 0.5587\n",
      "Epoch 15: val_loss improved from 2.10443 to 2.09967, saving model to results/network\\allopezr_2d_23x22_16_indian_pines_100.h5\n",
      "52/52 [==============================] - 2s 43ms/step - loss: 2.1512 - sparse_categorical_accuracy: 0.5585 - val_loss: 2.0997 - val_sparse_categorical_accuracy: 0.6159\n",
      "Epoch 16/100\n",
      "51/52 [============================>.] - ETA: 0s - loss: 2.0258 - sparse_categorical_accuracy: 0.5875\n",
      "Epoch 16: val_loss improved from 2.09967 to 2.05589, saving model to results/network\\allopezr_2d_23x22_16_indian_pines_100.h5\n",
      "52/52 [==============================] - 2s 43ms/step - loss: 2.0256 - sparse_categorical_accuracy: 0.5874 - val_loss: 2.0559 - val_sparse_categorical_accuracy: 0.6595\n",
      "Epoch 17/100\n",
      "51/52 [============================>.] - ETA: 0s - loss: 2.0659 - sparse_categorical_accuracy: 0.6007\n",
      "Epoch 17: val_loss did not improve from 2.05589\n",
      "52/52 [==============================] - 2s 43ms/step - loss: 2.0667 - sparse_categorical_accuracy: 0.6005 - val_loss: 2.1311 - val_sparse_categorical_accuracy: 0.6478\n",
      "Epoch 18/100\n",
      "51/52 [============================>.] - ETA: 0s - loss: 2.0632 - sparse_categorical_accuracy: 0.5889\n",
      "Epoch 18: val_loss improved from 2.05589 to 2.03209, saving model to results/network\\allopezr_2d_23x22_16_indian_pines_100.h5\n",
      "52/52 [==============================] - 2s 42ms/step - loss: 2.0628 - sparse_categorical_accuracy: 0.5888 - val_loss: 2.0321 - val_sparse_categorical_accuracy: 0.6498\n",
      "Epoch 19/100\n",
      "51/52 [============================>.] - ETA: 0s - loss: 2.0565 - sparse_categorical_accuracy: 0.5940\n",
      "Epoch 19: val_loss did not improve from 2.03209\n",
      "52/52 [==============================] - 2s 41ms/step - loss: 2.0562 - sparse_categorical_accuracy: 0.5942 - val_loss: 2.0721 - val_sparse_categorical_accuracy: 0.6416\n",
      "Epoch 20/100\n",
      "51/52 [============================>.] - ETA: 0s - loss: 1.9555 - sparse_categorical_accuracy: 0.6111\n",
      "Epoch 20: val_loss improved from 2.03209 to 1.96642, saving model to results/network\\allopezr_2d_23x22_16_indian_pines_100.h5\n",
      "52/52 [==============================] - 2s 45ms/step - loss: 1.9559 - sparse_categorical_accuracy: 0.6109 - val_loss: 1.9664 - val_sparse_categorical_accuracy: 0.6752\n",
      "Epoch 21/100\n",
      "51/52 [============================>.] - ETA: 0s - loss: 2.0017 - sparse_categorical_accuracy: 0.6098\n",
      "Epoch 21: val_loss did not improve from 1.96642\n",
      "52/52 [==============================] - 2s 41ms/step - loss: 2.0015 - sparse_categorical_accuracy: 0.6099 - val_loss: 2.0112 - val_sparse_categorical_accuracy: 0.6402\n",
      "Epoch 22/100\n",
      "51/52 [============================>.] - ETA: 0s - loss: 1.9774 - sparse_categorical_accuracy: 0.5943\n",
      "Epoch 22: val_loss did not improve from 1.96642\n",
      "52/52 [==============================] - 2s 41ms/step - loss: 1.9775 - sparse_categorical_accuracy: 0.5943 - val_loss: 1.9864 - val_sparse_categorical_accuracy: 0.6354\n",
      "Epoch 23/100\n",
      "51/52 [============================>.] - ETA: 0s - loss: 1.9352 - sparse_categorical_accuracy: 0.5998\n",
      "Epoch 23: val_loss did not improve from 1.96642\n",
      "52/52 [==============================] - 2s 41ms/step - loss: 1.9339 - sparse_categorical_accuracy: 0.6001 - val_loss: 1.9969 - val_sparse_categorical_accuracy: 0.6588\n",
      "Epoch 24/100\n",
      "51/52 [============================>.] - ETA: 0s - loss: 1.8655 - sparse_categorical_accuracy: 0.6217\n",
      "Epoch 24: val_loss improved from 1.96642 to 1.91597, saving model to results/network\\allopezr_2d_23x22_16_indian_pines_100.h5\n",
      "52/52 [==============================] - 2s 44ms/step - loss: 1.8651 - sparse_categorical_accuracy: 0.6220 - val_loss: 1.9160 - val_sparse_categorical_accuracy: 0.6722\n",
      "Epoch 25/100\n",
      "51/52 [============================>.] - ETA: 0s - loss: 1.8247 - sparse_categorical_accuracy: 0.6299\n",
      "Epoch 25: val_loss did not improve from 1.91597\n",
      "52/52 [==============================] - 2s 41ms/step - loss: 1.8254 - sparse_categorical_accuracy: 0.6299 - val_loss: 1.9341 - val_sparse_categorical_accuracy: 0.6704\n",
      "Epoch 26/100\n",
      "51/52 [============================>.] - ETA: 0s - loss: 1.8292 - sparse_categorical_accuracy: 0.6284\n",
      "Epoch 26: val_loss improved from 1.91597 to 1.89789, saving model to results/network\\allopezr_2d_23x22_16_indian_pines_100.h5\n",
      "52/52 [==============================] - 2s 44ms/step - loss: 1.8287 - sparse_categorical_accuracy: 0.6287 - val_loss: 1.8979 - val_sparse_categorical_accuracy: 0.6646\n",
      "Epoch 27/100\n",
      "51/52 [============================>.] - ETA: 0s - loss: 1.7862 - sparse_categorical_accuracy: 0.6462\n",
      "Epoch 27: val_loss did not improve from 1.89789\n",
      "52/52 [==============================] - 2s 41ms/step - loss: 1.7857 - sparse_categorical_accuracy: 0.6461 - val_loss: 1.9065 - val_sparse_categorical_accuracy: 0.6917\n",
      "Epoch 28/100\n",
      "51/52 [============================>.] - ETA: 0s - loss: 1.8213 - sparse_categorical_accuracy: 0.6410\n",
      "Epoch 28: val_loss improved from 1.89789 to 1.89503, saving model to results/network\\allopezr_2d_23x22_16_indian_pines_100.h5\n",
      "52/52 [==============================] - 2s 48ms/step - loss: 1.8221 - sparse_categorical_accuracy: 0.6407 - val_loss: 1.8950 - val_sparse_categorical_accuracy: 0.6814\n",
      "Epoch 29/100\n",
      "51/52 [============================>.] - ETA: 0s - loss: 1.7906 - sparse_categorical_accuracy: 0.6461\n",
      "Epoch 29: val_loss improved from 1.89503 to 1.83031, saving model to results/network\\allopezr_2d_23x22_16_indian_pines_100.h5\n",
      "52/52 [==============================] - 2s 43ms/step - loss: 1.7907 - sparse_categorical_accuracy: 0.6460 - val_loss: 1.8303 - val_sparse_categorical_accuracy: 0.6794\n",
      "Epoch 30/100\n",
      "51/52 [============================>.] - ETA: 0s - loss: 1.7517 - sparse_categorical_accuracy: 0.6525\n",
      "Epoch 30: val_loss improved from 1.83031 to 1.81984, saving model to results/network\\allopezr_2d_23x22_16_indian_pines_100.h5\n",
      "52/52 [==============================] - 2s 42ms/step - loss: 1.7515 - sparse_categorical_accuracy: 0.6523 - val_loss: 1.8198 - val_sparse_categorical_accuracy: 0.6893\n",
      "Epoch 31/100\n",
      "51/52 [============================>.] - ETA: 0s - loss: 1.7513 - sparse_categorical_accuracy: 0.6624\n",
      "Epoch 31: val_loss did not improve from 1.81984\n",
      "52/52 [==============================] - 2s 41ms/step - loss: 1.7512 - sparse_categorical_accuracy: 0.6623 - val_loss: 1.8379 - val_sparse_categorical_accuracy: 0.6886\n",
      "Epoch 32/100\n",
      "51/52 [============================>.] - ETA: 0s - loss: 1.7207 - sparse_categorical_accuracy: 0.6549\n",
      "Epoch 32: val_loss did not improve from 1.81984\n",
      "52/52 [==============================] - 2s 41ms/step - loss: 1.7203 - sparse_categorical_accuracy: 0.6548 - val_loss: 1.8303 - val_sparse_categorical_accuracy: 0.6790\n",
      "Epoch 33/100\n",
      "51/52 [============================>.] - ETA: 0s - loss: 1.7099 - sparse_categorical_accuracy: 0.6510\n",
      "Epoch 33: val_loss did not improve from 1.81984\n",
      "52/52 [==============================] - 2s 44ms/step - loss: 1.7099 - sparse_categorical_accuracy: 0.6512 - val_loss: 1.8217 - val_sparse_categorical_accuracy: 0.6842\n",
      "Epoch 34/100\n",
      "51/52 [============================>.] - ETA: 0s - loss: 1.6814 - sparse_categorical_accuracy: 0.6605\n",
      "Epoch 34: val_loss improved from 1.81984 to 1.78462, saving model to results/network\\allopezr_2d_23x22_16_indian_pines_100.h5\n",
      "52/52 [==============================] - 2s 43ms/step - loss: 1.6813 - sparse_categorical_accuracy: 0.6605 - val_loss: 1.7846 - val_sparse_categorical_accuracy: 0.6897\n",
      "Epoch 35/100\n",
      "51/52 [============================>.] - ETA: 0s - loss: 1.6845 - sparse_categorical_accuracy: 0.6681\n",
      "Epoch 35: val_loss improved from 1.78462 to 1.75512, saving model to results/network\\allopezr_2d_23x22_16_indian_pines_100.h5\n",
      "52/52 [==============================] - 2s 44ms/step - loss: 1.6845 - sparse_categorical_accuracy: 0.6682 - val_loss: 1.7551 - val_sparse_categorical_accuracy: 0.7000\n",
      "Epoch 36/100\n",
      "51/52 [============================>.] - ETA: 0s - loss: 1.6622 - sparse_categorical_accuracy: 0.6731\n",
      "Epoch 36: val_loss did not improve from 1.75512\n",
      "52/52 [==============================] - 2s 41ms/step - loss: 1.6622 - sparse_categorical_accuracy: 0.6733 - val_loss: 1.8189 - val_sparse_categorical_accuracy: 0.6904\n",
      "Epoch 37/100\n",
      "51/52 [============================>.] - ETA: 0s - loss: 1.6719 - sparse_categorical_accuracy: 0.6618\n",
      "Epoch 37: val_loss did not improve from 1.75512\n",
      "52/52 [==============================] - 2s 41ms/step - loss: 1.6713 - sparse_categorical_accuracy: 0.6620 - val_loss: 1.7580 - val_sparse_categorical_accuracy: 0.6777\n",
      "Epoch 38/100\n",
      "51/52 [============================>.] - ETA: 0s - loss: 1.6105 - sparse_categorical_accuracy: 0.6623\n",
      "Epoch 38: val_loss improved from 1.75512 to 1.67422, saving model to results/network\\allopezr_2d_23x22_16_indian_pines_100.h5\n",
      "52/52 [==============================] - 2s 47ms/step - loss: 1.6106 - sparse_categorical_accuracy: 0.6625 - val_loss: 1.6742 - val_sparse_categorical_accuracy: 0.6650\n",
      "Epoch 39/100\n",
      "51/52 [============================>.] - ETA: 0s - loss: 1.5971 - sparse_categorical_accuracy: 0.6690\n",
      "Epoch 39: val_loss did not improve from 1.67422\n",
      "52/52 [==============================] - 2s 41ms/step - loss: 1.5970 - sparse_categorical_accuracy: 0.6688 - val_loss: 1.7675 - val_sparse_categorical_accuracy: 0.6759\n",
      "Epoch 40/100\n",
      "51/52 [============================>.] - ETA: 0s - loss: 1.5844 - sparse_categorical_accuracy: 0.6685\n",
      "Epoch 40: val_loss did not improve from 1.67422\n",
      "52/52 [==============================] - 2s 42ms/step - loss: 1.5838 - sparse_categorical_accuracy: 0.6683 - val_loss: 1.7618 - val_sparse_categorical_accuracy: 0.6780\n",
      "Epoch 41/100\n",
      "51/52 [============================>.] - ETA: 0s - loss: 1.5473 - sparse_categorical_accuracy: 0.6806\n",
      "Epoch 41: val_loss improved from 1.67422 to 1.65803, saving model to results/network\\allopezr_2d_23x22_16_indian_pines_100.h5\n",
      "52/52 [==============================] - 2s 44ms/step - loss: 1.5467 - sparse_categorical_accuracy: 0.6808 - val_loss: 1.6580 - val_sparse_categorical_accuracy: 0.7106\n",
      "Epoch 42/100\n",
      "51/52 [============================>.] - ETA: 0s - loss: 1.5295 - sparse_categorical_accuracy: 0.6798\n",
      "Epoch 42: val_loss did not improve from 1.65803\n",
      "52/52 [==============================] - 2s 41ms/step - loss: 1.5294 - sparse_categorical_accuracy: 0.6796 - val_loss: 1.7247 - val_sparse_categorical_accuracy: 0.6880\n",
      "Epoch 43/100\n",
      "51/52 [============================>.] - ETA: 0s - loss: 1.5617 - sparse_categorical_accuracy: 0.6747\n",
      "Epoch 43: val_loss did not improve from 1.65803\n",
      "52/52 [==============================] - 2s 43ms/step - loss: 1.5620 - sparse_categorical_accuracy: 0.6749 - val_loss: 1.7799 - val_sparse_categorical_accuracy: 0.6687\n",
      "Epoch 44/100\n",
      "51/52 [============================>.] - ETA: 0s - loss: 1.5749 - sparse_categorical_accuracy: 0.6681\n",
      "Epoch 44: val_loss did not improve from 1.65803\n",
      "52/52 [==============================] - 2s 41ms/step - loss: 1.5733 - sparse_categorical_accuracy: 0.6684 - val_loss: 1.7389 - val_sparse_categorical_accuracy: 0.6770\n",
      "Epoch 45/100\n",
      "51/52 [============================>.] - ETA: 0s - loss: 1.4909 - sparse_categorical_accuracy: 0.6843\n",
      "Epoch 45: val_loss improved from 1.65803 to 1.63138, saving model to results/network\\allopezr_2d_23x22_16_indian_pines_100.h5\n",
      "52/52 [==============================] - 3s 56ms/step - loss: 1.4901 - sparse_categorical_accuracy: 0.6844 - val_loss: 1.6314 - val_sparse_categorical_accuracy: 0.6855\n",
      "Epoch 46/100\n",
      "51/52 [============================>.] - ETA: 0s - loss: 1.4918 - sparse_categorical_accuracy: 0.6867\n",
      "Epoch 46: val_loss did not improve from 1.63138\n",
      "52/52 [==============================] - 2s 43ms/step - loss: 1.4926 - sparse_categorical_accuracy: 0.6863 - val_loss: 1.7589 - val_sparse_categorical_accuracy: 0.6945\n",
      "Epoch 47/100\n",
      "51/52 [============================>.] - ETA: 0s - loss: 1.5497 - sparse_categorical_accuracy: 0.6759\n",
      "Epoch 47: val_loss did not improve from 1.63138\n",
      "52/52 [==============================] - 2s 42ms/step - loss: 1.5501 - sparse_categorical_accuracy: 0.6759 - val_loss: 1.7799 - val_sparse_categorical_accuracy: 0.6739\n",
      "Epoch 48/100\n",
      "51/52 [============================>.] - ETA: 0s - loss: 1.5266 - sparse_categorical_accuracy: 0.6761\n",
      "Epoch 48: val_loss did not improve from 1.63138\n",
      "52/52 [==============================] - 2s 41ms/step - loss: 1.5257 - sparse_categorical_accuracy: 0.6761 - val_loss: 1.7237 - val_sparse_categorical_accuracy: 0.6845\n",
      "Epoch 49/100\n",
      "51/52 [============================>.] - ETA: 0s - loss: 1.4486 - sparse_categorical_accuracy: 0.6896\n",
      "Epoch 49: val_loss did not improve from 1.63138\n",
      "52/52 [==============================] - 2s 42ms/step - loss: 1.4486 - sparse_categorical_accuracy: 0.6896 - val_loss: 1.6637 - val_sparse_categorical_accuracy: 0.6845\n",
      "Epoch 50/100\n",
      "51/52 [============================>.] - ETA: 0s - loss: 1.4604 - sparse_categorical_accuracy: 0.6886\n",
      "Epoch 50: val_loss did not improve from 1.63138\n",
      "52/52 [==============================] - 2s 42ms/step - loss: 1.4601 - sparse_categorical_accuracy: 0.6888 - val_loss: 1.6971 - val_sparse_categorical_accuracy: 0.6931\n",
      "Epoch 51/100\n",
      "51/52 [============================>.] - ETA: 0s - loss: 1.4564 - sparse_categorical_accuracy: 0.6977\n",
      "Epoch 51: val_loss improved from 1.63138 to 1.63044, saving model to results/network\\allopezr_2d_23x22_16_indian_pines_100.h5\n",
      "52/52 [==============================] - 2s 46ms/step - loss: 1.4559 - sparse_categorical_accuracy: 0.6979 - val_loss: 1.6304 - val_sparse_categorical_accuracy: 0.6886\n",
      "Epoch 52/100\n",
      "51/52 [============================>.] - ETA: 0s - loss: 1.4633 - sparse_categorical_accuracy: 0.6864\n",
      "Epoch 52: val_loss did not improve from 1.63044\n",
      "52/52 [==============================] - 2s 41ms/step - loss: 1.4636 - sparse_categorical_accuracy: 0.6863 - val_loss: 1.7266 - val_sparse_categorical_accuracy: 0.6814\n",
      "Epoch 53/100\n",
      "51/52 [============================>.] - ETA: 0s - loss: 1.4692 - sparse_categorical_accuracy: 0.6908\n",
      "Epoch 53: val_loss did not improve from 1.63044\n",
      "52/52 [==============================] - 2s 42ms/step - loss: 1.4694 - sparse_categorical_accuracy: 0.6908 - val_loss: 1.6676 - val_sparse_categorical_accuracy: 0.7044\n",
      "Epoch 54/100\n",
      "51/52 [============================>.] - ETA: 0s - loss: 1.4228 - sparse_categorical_accuracy: 0.7040\n",
      "Epoch 54: val_loss did not improve from 1.63044\n",
      "52/52 [==============================] - 2s 44ms/step - loss: 1.4222 - sparse_categorical_accuracy: 0.7041 - val_loss: 1.6609 - val_sparse_categorical_accuracy: 0.7051\n",
      "Epoch 55/100\n",
      "51/52 [============================>.] - ETA: 0s - loss: 1.4498 - sparse_categorical_accuracy: 0.6958\n",
      "Epoch 55: val_loss did not improve from 1.63044\n",
      "52/52 [==============================] - 2s 41ms/step - loss: 1.4492 - sparse_categorical_accuracy: 0.6957 - val_loss: 1.7028 - val_sparse_categorical_accuracy: 0.6982\n",
      "Epoch 56/100\n",
      "51/52 [============================>.] - ETA: 0s - loss: 1.4257 - sparse_categorical_accuracy: 0.6988\n",
      "Epoch 56: val_loss did not improve from 1.63044\n",
      "52/52 [==============================] - 2s 42ms/step - loss: 1.4261 - sparse_categorical_accuracy: 0.6984 - val_loss: 1.7304 - val_sparse_categorical_accuracy: 0.6873\n",
      "Epoch 57/100\n",
      "51/52 [============================>.] - ETA: 0s - loss: 1.4228 - sparse_categorical_accuracy: 0.6950\n",
      "Epoch 57: val_loss did not improve from 1.63044\n",
      "52/52 [==============================] - 2s 42ms/step - loss: 1.4227 - sparse_categorical_accuracy: 0.6950 - val_loss: 1.7094 - val_sparse_categorical_accuracy: 0.6842\n",
      "Epoch 58/100\n",
      "51/52 [============================>.] - ETA: 0s - loss: 1.4280 - sparse_categorical_accuracy: 0.6998\n",
      "Epoch 58: val_loss did not improve from 1.63044\n",
      "52/52 [==============================] - 2s 42ms/step - loss: 1.4278 - sparse_categorical_accuracy: 0.7001 - val_loss: 1.7085 - val_sparse_categorical_accuracy: 0.6952\n",
      "Epoch 59/100\n",
      "51/52 [============================>.] - ETA: 0s - loss: 1.4008 - sparse_categorical_accuracy: 0.7099\n",
      "Epoch 59: val_loss did not improve from 1.63044\n",
      "52/52 [==============================] - 2s 42ms/step - loss: 1.4014 - sparse_categorical_accuracy: 0.7096 - val_loss: 1.7361 - val_sparse_categorical_accuracy: 0.7068\n",
      "Epoch 60/100\n",
      "51/52 [============================>.] - ETA: 0s - loss: 1.3961 - sparse_categorical_accuracy: 0.7122\n",
      "Epoch 60: val_loss did not improve from 1.63044\n",
      "52/52 [==============================] - 2s 42ms/step - loss: 1.3964 - sparse_categorical_accuracy: 0.7121 - val_loss: 1.7237 - val_sparse_categorical_accuracy: 0.7089\n",
      "Epoch 61/100\n",
      "51/52 [============================>.] - ETA: 0s - loss: 1.3827 - sparse_categorical_accuracy: 0.7159\n",
      "Epoch 61: val_loss did not improve from 1.63044\n",
      "52/52 [==============================] - 2s 43ms/step - loss: 1.3830 - sparse_categorical_accuracy: 0.7161 - val_loss: 1.7513 - val_sparse_categorical_accuracy: 0.6921\n",
      "Epoch 62/100\n",
      "51/52 [============================>.] - ETA: 0s - loss: 1.4558 - sparse_categorical_accuracy: 0.7062\n",
      "Epoch 62: val_loss did not improve from 1.63044\n",
      "52/52 [==============================] - 2s 41ms/step - loss: 1.4562 - sparse_categorical_accuracy: 0.7059 - val_loss: 1.8389 - val_sparse_categorical_accuracy: 0.6897\n",
      "Epoch 63/100\n",
      "51/52 [============================>.] - ETA: 0s - loss: 1.4214 - sparse_categorical_accuracy: 0.7107\n",
      "Epoch 63: val_loss did not improve from 1.63044\n",
      "52/52 [==============================] - 2s 41ms/step - loss: 1.4210 - sparse_categorical_accuracy: 0.7108 - val_loss: 1.7837 - val_sparse_categorical_accuracy: 0.6917\n",
      "Epoch 64/100\n",
      "51/52 [============================>.] - ETA: 0s - loss: 1.3750 - sparse_categorical_accuracy: 0.7179\n",
      "Epoch 64: val_loss did not improve from 1.63044\n",
      "52/52 [==============================] - 2s 41ms/step - loss: 1.3734 - sparse_categorical_accuracy: 0.7183 - val_loss: 1.6923 - val_sparse_categorical_accuracy: 0.7051\n",
      "Epoch 65/100\n",
      "51/52 [============================>.] - ETA: 0s - loss: 1.3395 - sparse_categorical_accuracy: 0.7151\n",
      "Epoch 65: val_loss did not improve from 1.63044\n",
      "52/52 [==============================] - 2s 42ms/step - loss: 1.3394 - sparse_categorical_accuracy: 0.7153 - val_loss: 1.6733 - val_sparse_categorical_accuracy: 0.7041\n",
      "Epoch 66/100\n",
      "51/52 [============================>.] - ETA: 0s - loss: 1.3365 - sparse_categorical_accuracy: 0.7266\n",
      "Epoch 66: val_loss did not improve from 1.63044\n",
      "52/52 [==============================] - 2s 42ms/step - loss: 1.3365 - sparse_categorical_accuracy: 0.7267 - val_loss: 1.7485 - val_sparse_categorical_accuracy: 0.7031\n",
      "Epoch 67/100\n",
      "51/52 [============================>.] - ETA: 0s - loss: 1.3186 - sparse_categorical_accuracy: 0.7250\n",
      "Epoch 67: val_loss did not improve from 1.63044\n",
      "52/52 [==============================] - 2s 41ms/step - loss: 1.3183 - sparse_categorical_accuracy: 0.7248 - val_loss: 1.6828 - val_sparse_categorical_accuracy: 0.7044\n",
      "Epoch 68/100\n",
      "51/52 [============================>.] - ETA: 0s - loss: 1.3098 - sparse_categorical_accuracy: 0.7281\n",
      "Epoch 68: val_loss did not improve from 1.63044\n",
      "52/52 [==============================] - 2s 44ms/step - loss: 1.3102 - sparse_categorical_accuracy: 0.7282 - val_loss: 1.7761 - val_sparse_categorical_accuracy: 0.7007\n",
      "Epoch 69/100\n",
      "51/52 [============================>.] - ETA: 0s - loss: 1.3353 - sparse_categorical_accuracy: 0.7255\n",
      "Epoch 69: val_loss did not improve from 1.63044\n",
      "52/52 [==============================] - 2s 41ms/step - loss: 1.3350 - sparse_categorical_accuracy: 0.7256 - val_loss: 1.7085 - val_sparse_categorical_accuracy: 0.7010\n",
      "Epoch 70/100\n",
      "51/52 [============================>.] - ETA: 0s - loss: 1.3086 - sparse_categorical_accuracy: 0.7266\n",
      "Epoch 70: val_loss did not improve from 1.63044\n",
      "52/52 [==============================] - 2s 42ms/step - loss: 1.3089 - sparse_categorical_accuracy: 0.7264 - val_loss: 1.7466 - val_sparse_categorical_accuracy: 0.6938\n",
      "Epoch 71/100\n",
      "51/52 [============================>.] - ETA: 0s - loss: 1.2890 - sparse_categorical_accuracy: 0.7290\n",
      "Epoch 71: val_loss did not improve from 1.63044\n",
      "52/52 [==============================] - 2s 40ms/step - loss: 1.2894 - sparse_categorical_accuracy: 0.7288 - val_loss: 1.7599 - val_sparse_categorical_accuracy: 0.6797\n",
      "Epoch 72/100\n",
      "51/52 [============================>.] - ETA: 0s - loss: 1.3016 - sparse_categorical_accuracy: 0.7209\n",
      "Epoch 72: val_loss did not improve from 1.63044\n",
      "52/52 [==============================] - 2s 40ms/step - loss: 1.3011 - sparse_categorical_accuracy: 0.7211 - val_loss: 1.7304 - val_sparse_categorical_accuracy: 0.6862\n",
      "Epoch 73/100\n",
      "51/52 [============================>.] - ETA: 0s - loss: 1.2978 - sparse_categorical_accuracy: 0.7248\n",
      "Epoch 73: val_loss did not improve from 1.63044\n",
      "52/52 [==============================] - 2s 41ms/step - loss: 1.2983 - sparse_categorical_accuracy: 0.7245 - val_loss: 1.7342 - val_sparse_categorical_accuracy: 0.7003\n",
      "Epoch 74/100\n",
      "51/52 [============================>.] - ETA: 0s - loss: 1.2884 - sparse_categorical_accuracy: 0.7301\n",
      "Epoch 74: val_loss did not improve from 1.63044\n",
      "52/52 [==============================] - 2s 40ms/step - loss: 1.2888 - sparse_categorical_accuracy: 0.7301 - val_loss: 1.7818 - val_sparse_categorical_accuracy: 0.6797\n",
      "Epoch 75/100\n",
      "51/52 [============================>.] - ETA: 0s - loss: 1.3074 - sparse_categorical_accuracy: 0.7284\n",
      "Epoch 75: val_loss did not improve from 1.63044\n",
      "52/52 [==============================] - 2s 40ms/step - loss: 1.3074 - sparse_categorical_accuracy: 0.7286 - val_loss: 1.8351 - val_sparse_categorical_accuracy: 0.6783\n",
      "Epoch 76/100\n",
      "51/52 [============================>.] - ETA: 0s - loss: 1.3251 - sparse_categorical_accuracy: 0.7163\n",
      "Epoch 76: val_loss did not improve from 1.63044\n",
      "52/52 [==============================] - 2s 40ms/step - loss: 1.3249 - sparse_categorical_accuracy: 0.7163 - val_loss: 1.8103 - val_sparse_categorical_accuracy: 0.6801\n",
      "Epoch 77/100\n",
      "51/52 [============================>.] - ETA: 0s - loss: 1.2754 - sparse_categorical_accuracy: 0.7377\n",
      "Epoch 77: val_loss did not improve from 1.63044\n",
      "52/52 [==============================] - 2s 41ms/step - loss: 1.2758 - sparse_categorical_accuracy: 0.7377 - val_loss: 1.8370 - val_sparse_categorical_accuracy: 0.6924\n",
      "Epoch 78/100\n",
      "51/52 [============================>.] - ETA: 0s - loss: 1.2776 - sparse_categorical_accuracy: 0.7439\n",
      "Epoch 78: val_loss did not improve from 1.63044\n",
      "52/52 [==============================] - 2s 41ms/step - loss: 1.2778 - sparse_categorical_accuracy: 0.7438 - val_loss: 1.8579 - val_sparse_categorical_accuracy: 0.6749\n",
      "Epoch 79/100\n",
      "51/52 [============================>.] - ETA: 0s - loss: 1.3011 - sparse_categorical_accuracy: 0.7387\n",
      "Epoch 79: val_loss did not improve from 1.63044\n",
      "52/52 [==============================] - 2s 42ms/step - loss: 1.3015 - sparse_categorical_accuracy: 0.7388 - val_loss: 1.9312 - val_sparse_categorical_accuracy: 0.6821\n",
      "Epoch 80/100\n",
      "51/52 [============================>.] - ETA: 0s - loss: 1.2760 - sparse_categorical_accuracy: 0.7395\n",
      "Epoch 80: val_loss did not improve from 1.63044\n",
      "52/52 [==============================] - 2s 42ms/step - loss: 1.2763 - sparse_categorical_accuracy: 0.7394 - val_loss: 1.9445 - val_sparse_categorical_accuracy: 0.6677\n",
      "Epoch 81/100\n",
      "51/52 [============================>.] - ETA: 0s - loss: 1.3137 - sparse_categorical_accuracy: 0.7306\n",
      "Epoch 81: val_loss did not improve from 1.63044\n",
      "52/52 [==============================] - 2s 41ms/step - loss: 1.3142 - sparse_categorical_accuracy: 0.7303 - val_loss: 1.9712 - val_sparse_categorical_accuracy: 0.6694\n",
      "Epoch 82/100\n",
      "51/52 [============================>.] - ETA: 0s - loss: 1.2846 - sparse_categorical_accuracy: 0.7408\n",
      "Epoch 82: val_loss did not improve from 1.63044\n",
      "52/52 [==============================] - 2s 42ms/step - loss: 1.2851 - sparse_categorical_accuracy: 0.7406 - val_loss: 1.9521 - val_sparse_categorical_accuracy: 0.6787\n",
      "Epoch 83/100\n",
      "51/52 [============================>.] - ETA: 0s - loss: 1.2687 - sparse_categorical_accuracy: 0.7470\n",
      "Epoch 83: val_loss did not improve from 1.63044\n",
      "52/52 [==============================] - 2s 41ms/step - loss: 1.2676 - sparse_categorical_accuracy: 0.7475 - val_loss: 1.9483 - val_sparse_categorical_accuracy: 0.6818\n",
      "Epoch 84/100\n",
      "51/52 [============================>.] - ETA: 0s - loss: 1.2637 - sparse_categorical_accuracy: 0.7454\n",
      "Epoch 84: val_loss did not improve from 1.63044\n",
      "52/52 [==============================] - 2s 43ms/step - loss: 1.2635 - sparse_categorical_accuracy: 0.7455 - val_loss: 1.9122 - val_sparse_categorical_accuracy: 0.6883\n",
      "Epoch 85/100\n",
      "51/52 [============================>.] - ETA: 0s - loss: 1.2746 - sparse_categorical_accuracy: 0.7440\n",
      "Epoch 85: val_loss did not improve from 1.63044\n",
      "52/52 [==============================] - 2s 41ms/step - loss: 1.2744 - sparse_categorical_accuracy: 0.7442 - val_loss: 1.9836 - val_sparse_categorical_accuracy: 0.6650\n",
      "Epoch 86/100\n",
      "51/52 [============================>.] - ETA: 0s - loss: 1.2771 - sparse_categorical_accuracy: 0.7356\n",
      "Epoch 86: val_loss did not improve from 1.63044\n",
      "52/52 [==============================] - 2s 41ms/step - loss: 1.2775 - sparse_categorical_accuracy: 0.7357 - val_loss: 1.9198 - val_sparse_categorical_accuracy: 0.6564\n",
      "Epoch 87/100\n",
      "51/52 [============================>.] - ETA: 0s - loss: 1.2558 - sparse_categorical_accuracy: 0.7361\n",
      "Epoch 87: val_loss did not improve from 1.63044\n",
      "52/52 [==============================] - 2s 42ms/step - loss: 1.2553 - sparse_categorical_accuracy: 0.7362 - val_loss: 1.9188 - val_sparse_categorical_accuracy: 0.6728\n",
      "Epoch 88/100\n",
      "51/52 [============================>.] - ETA: 0s - loss: 1.2460 - sparse_categorical_accuracy: 0.7331\n",
      "Epoch 88: val_loss did not improve from 1.63044\n",
      "52/52 [==============================] - 2s 41ms/step - loss: 1.2468 - sparse_categorical_accuracy: 0.7329 - val_loss: 1.9350 - val_sparse_categorical_accuracy: 0.6571\n",
      "Epoch 89/100\n",
      "51/52 [============================>.] - ETA: 0s - loss: 1.2815 - sparse_categorical_accuracy: 0.7336\n",
      "Epoch 89: val_loss did not improve from 1.63044\n",
      "52/52 [==============================] - 2s 42ms/step - loss: 1.2815 - sparse_categorical_accuracy: 0.7336 - val_loss: 2.0073 - val_sparse_categorical_accuracy: 0.6591\n",
      "Epoch 90/100\n",
      "51/52 [============================>.] - ETA: 0s - loss: 1.2792 - sparse_categorical_accuracy: 0.7282\n",
      "Epoch 90: val_loss did not improve from 1.63044\n",
      "52/52 [==============================] - 2s 42ms/step - loss: 1.2790 - sparse_categorical_accuracy: 0.7281 - val_loss: 2.0121 - val_sparse_categorical_accuracy: 0.6536\n",
      "Epoch 91/100\n",
      "51/52 [============================>.] - ETA: 0s - loss: 1.2586 - sparse_categorical_accuracy: 0.7405\n",
      "Epoch 91: val_loss did not improve from 1.63044\n",
      "52/52 [==============================] - 2s 42ms/step - loss: 1.2589 - sparse_categorical_accuracy: 0.7404 - val_loss: 1.9750 - val_sparse_categorical_accuracy: 0.6663\n",
      "Epoch 92/100\n",
      "51/52 [============================>.] - ETA: 0s - loss: 1.2531 - sparse_categorical_accuracy: 0.7392\n",
      "Epoch 92: val_loss did not improve from 1.63044\n",
      "52/52 [==============================] - 2s 41ms/step - loss: 1.2531 - sparse_categorical_accuracy: 0.7394 - val_loss: 1.9569 - val_sparse_categorical_accuracy: 0.6553\n",
      "Epoch 93/100\n",
      "51/52 [============================>.] - ETA: 0s - loss: 1.2476 - sparse_categorical_accuracy: 0.7363\n",
      "Epoch 93: val_loss did not improve from 1.63044\n",
      "52/52 [==============================] - 2s 41ms/step - loss: 1.2474 - sparse_categorical_accuracy: 0.7366 - val_loss: 2.0102 - val_sparse_categorical_accuracy: 0.6488\n",
      "Epoch 94/100\n",
      "51/52 [============================>.] - ETA: 0s - loss: 1.2524 - sparse_categorical_accuracy: 0.7411\n",
      "Epoch 94: val_loss did not improve from 1.63044\n",
      "52/52 [==============================] - 2s 41ms/step - loss: 1.2528 - sparse_categorical_accuracy: 0.7409 - val_loss: 2.0188 - val_sparse_categorical_accuracy: 0.6615\n",
      "Epoch 95/100\n",
      "51/52 [============================>.] - ETA: 0s - loss: 1.2364 - sparse_categorical_accuracy: 0.7460\n",
      "Epoch 95: val_loss did not improve from 1.63044\n",
      "52/52 [==============================] - 2s 41ms/step - loss: 1.2372 - sparse_categorical_accuracy: 0.7458 - val_loss: 1.9912 - val_sparse_categorical_accuracy: 0.6701\n",
      "Epoch 96/100\n",
      "51/52 [============================>.] - ETA: 0s - loss: 1.2447 - sparse_categorical_accuracy: 0.7422\n",
      "Epoch 96: val_loss did not improve from 1.63044\n",
      "52/52 [==============================] - 2s 44ms/step - loss: 1.2444 - sparse_categorical_accuracy: 0.7426 - val_loss: 1.9788 - val_sparse_categorical_accuracy: 0.6728\n",
      "Epoch 97/100\n",
      "51/52 [============================>.] - ETA: 0s - loss: 1.2116 - sparse_categorical_accuracy: 0.7396\n",
      "Epoch 97: val_loss did not improve from 1.63044\n",
      "52/52 [==============================] - 2s 41ms/step - loss: 1.2113 - sparse_categorical_accuracy: 0.7396 - val_loss: 1.9788 - val_sparse_categorical_accuracy: 0.6698\n",
      "Epoch 98/100\n",
      "51/52 [============================>.] - ETA: 0s - loss: 1.2287 - sparse_categorical_accuracy: 0.7431\n",
      "Epoch 98: val_loss did not improve from 1.63044\n",
      "52/52 [==============================] - 2s 41ms/step - loss: 1.2288 - sparse_categorical_accuracy: 0.7429 - val_loss: 1.9702 - val_sparse_categorical_accuracy: 0.6608\n",
      "Epoch 99/100\n",
      "51/52 [============================>.] - ETA: 0s - loss: 1.2210 - sparse_categorical_accuracy: 0.7390\n",
      "Epoch 99: val_loss did not improve from 1.63044\n",
      "52/52 [==============================] - 2s 41ms/step - loss: 1.2203 - sparse_categorical_accuracy: 0.7393 - val_loss: 2.0226 - val_sparse_categorical_accuracy: 0.6660\n",
      "Epoch 100/100\n",
      "51/52 [============================>.] - ETA: 0s - loss: 1.2347 - sparse_categorical_accuracy: 0.7454\n",
      "Epoch 100: val_loss did not improve from 1.63044\n",
      "52/52 [==============================] - 2s 40ms/step - loss: 1.2350 - sparse_categorical_accuracy: 0.7454 - val_loss: 2.0340 - val_sparse_categorical_accuracy: 0.6677\n",
      "Training took 222.43469905853271 seconds\n",
      "Samples: 29130, Time: 222.43469905853271\n",
      "|████████████████████████████████████████| 0 in 0.1s (0.00/s)                                                           \n"
     ]
    }
   ],
   "source": [
    "max_samples = 100000\n",
    "starting_index = 0\n",
    "\n",
    "while True:\n",
    "    X_train, y_train = hc_set.split_train(patch_size=config.patch_size, max_train_samples=max_samples,\n",
    "                                          starting_index=starting_index, remove=False)\n",
    "\n",
    "    if len(X_train) > 0:\n",
    "        y_train = reduce_labels_center(y_train)\n",
    "        X_train, y_train = remove_labels(X_train, y_train, [ground_label])\n",
    "        #(patch, patch_label), _, _ = balance_classes(X_train, y_train, reduce=True, clustering=False, strategy=sampling_strategy)\n",
    "        patch, patch_label = X_train, y_train\n",
    "\n",
    "        # Remove patches with label 255\n",
    "        # indices = np.where(patch_label != 255)\n",
    "        # patch = patch[indices]\n",
    "        # patch_label = patch_label[indices]\n",
    "\n",
    "        #rendering.render_mask_histogram(patch_label)\n",
    "\n",
    "        X_train_augment, y_train_augmented = augment_chunks(patch, patch_label)\n",
    "        history.append_history(run_model(model, X_train_augment, y_train_augmented,\n",
    "                                         validation_split=validation_split, callbacks=callbacks).history,\n",
    "                               training_callback=time_callback, samples=X_train_augment)\n",
    "\n",
    "        del X_train_augment, y_train_augmented\n",
    "        del patch, patch_label\n",
    "    else:\n",
    "        break\n",
    "\n",
    "    del X_train, y_train\n",
    "    starting_index += max_samples\n",
    "\n",
    "    gc.collect()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 1s 40ms/step\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0104 - sparse_categorical_accuracy: 0.9875\n",
      "Test Loss: 0.010449012741446495, Test Accuracy: 0.987500011920929\n"
     ]
    }
   ],
   "source": [
    "test_prediction_prob = model.predict(X_test)\n",
    "test_prediction = np.argmax(test_prediction_prob, axis=1)\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Test Loss: \" + str(test_loss) + \", Test Accuracy: \" + str(test_accuracy))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
