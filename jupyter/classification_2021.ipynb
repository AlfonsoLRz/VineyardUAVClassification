{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%pylab is deprecated, use %matplotlib inline and import the required libraries.\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\allopezr\\Documents\\GitHub\\VineyardUAVClassification\\venv\\lib\\site-packages\\IPython\\core\\magics\\pylab.py:162: UserWarning:\n",
      "\n",
      "pylab import has clobbered these variables: ['random', 'shuffle', 'inf', 'copy']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 Physical GPUs, 2 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from albumentations import (\n",
    "    Compose, RandomBrightness, JpegCompression, HueSaturationValue, RandomContrast, HorizontalFlip,\n",
    "    Rotate, VerticalFlip, Crop, PixelDropout, CropAndPad, RandomBrightnessContrast\n",
    ")\n",
    "import config\n",
    "import paths\n",
    "import randomness\n",
    "from cnn_builder import *\n",
    "from config import *\n",
    "from dataset_functions import *\n",
    "from functools import partial\n",
    "from hypercube_set import HypercubeSet\n",
    "from hypercube_loader import *\n",
    "import numpy as np\n",
    "import random\n",
    "import randomness\n",
    "import rendering\n",
    "import training_history\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"PATH\"] += os.pathsep + 'C:/Program Files/Graphviz/bin/'\n",
    "os.chdir(os.getcwd().split(\"jupyter\")[0])\n",
    "\n",
    "inf = 2e32\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%pylab inline\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "        logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "font_mapping = {'family': 'Palatino Linotype', 'weight': 'normal', 'size': 11}\n",
    "plt.rc('font', **font_mapping)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading media/Mateus_2022/red\\raw_112_rf.hdr ...\n",
      "Hypercube shape: (1872, 640, 270)\n",
      "{(0, 0, 0): 0, (255, 128, 255): 1, (192, 128, 255): 2, (255, 128, 0): 3, (255, 255, 128): 4, (128, 255, 0): 5, (128, 255, 128): 6, (128, 255, 255): 7, (128, 128, 255): 8}\n",
      "Reading media/Mateus_2022/red\\raw_1984_rf.hdr ...\n",
      "Hypercube shape: (1920, 640, 270)\n",
      "{(0, 0, 0): 0, (255, 128, 255): 1, (192, 128, 255): 2, (255, 128, 0): 3, (255, 255, 128): 4, (128, 255, 0): 5, (128, 255, 128): 6, (128, 255, 255): 7, (128, 128, 255): 8}\n",
      "Reading media/Mateus_2022/red\\raw_3904_rf.hdr ...\n",
      "Hypercube shape: (1840, 640, 270)\n",
      "{(0, 0, 0): 0, (255, 128, 255): 1, (192, 128, 255): 2, (255, 128, 0): 3, (255, 255, 128): 4, (128, 255, 0): 5, (128, 255, 128): 6, (128, 255, 255): 7, (128, 128, 255): 8}\n",
      "Reading media/Mateus_2022/red\\raw_5744_rf.hdr ...\n",
      "Hypercube shape: (1840, 640, 270)\n",
      "{(0, 0, 0): 0, (255, 128, 255): 1, (192, 128, 255): 2, (255, 128, 0): 3, (255, 255, 128): 4, (128, 255, 0): 5, (128, 255, 128): 6, (128, 255, 255): 7, (128, 128, 255): 8}\n",
      "Reading media/Mateus_2022/red\\raw_7584_rf.hdr ...\n",
      "Hypercube shape: (1840, 640, 270)\n",
      "{(0, 0, 0): 0, (255, 128, 255): 1, (192, 128, 255): 2, (255, 128, 0): 3, (255, 255, 128): 4, (128, 255, 0): 5, (128, 255, 128): 6, (128, 255, 255): 7, (128, 128, 255): 8}\n",
      "Reading media/Mateus_2022/white\\raw_11888_rf.hdr ...\n",
      "Hypercube shape: (1152, 640, 270)\n",
      "{(0, 0, 0): 0, (128, 255, 128): 1, (128, 255, 255): 2, (128, 128, 255): 3}\n",
      "Reading media/Mateus_2022/white\\raw_13040_rf.hdr ...\n",
      "Hypercube shape: (2000, 640, 270)\n",
      "{(0, 0, 0): 0, (128, 255, 128): 1, (128, 255, 255): 2, (128, 128, 255): 3}\n",
      "Reading media/Mateus_2022/white\\raw_15040_rf.hdr ...\n",
      "Hypercube shape: (1024, 640, 270)\n",
      "{(0, 0, 0): 0, (128, 255, 128): 1, (128, 255, 255): 2, (128, 128, 255): 3, (128, 255, 0): 4}\n",
      "Reading media/Mateus_2022/white\\raw_16064_rf.hdr ...\n",
      "Hypercube shape: (2000, 640, 270)\n",
      "{(0, 0, 0): 0, (128, 255, 128): 1, (128, 255, 255): 2, (128, 128, 255): 3, (128, 255, 0): 4, (255, 255, 128): 5, (255, 128, 0): 6, (192, 128, 255): 7, (255, 128, 255): 8, (0, 0, 255): 9}\n",
      "Reading media/Mateus_2022/white\\raw_18064_rf.hdr ...\n",
      "Hypercube shape: (944, 640, 270)\n",
      "{(0, 0, 0): 0, (128, 255, 128): 1, (128, 255, 255): 2, (128, 128, 255): 3, (128, 255, 0): 4, (255, 255, 128): 5, (255, 128, 0): 6, (192, 128, 255): 7, (255, 128, 255): 8, (0, 0, 255): 9}\n",
      "Reading media/Mateus_2022/white\\raw_19008_rf.hdr ...\n",
      "Hypercube shape: (2000, 640, 270)\n",
      "{(0, 0, 0): 0, (128, 255, 128): 1, (128, 255, 255): 2, (128, 128, 255): 3, (128, 255, 0): 4, (255, 255, 128): 5, (255, 128, 0): 6, (192, 128, 255): 7, (255, 128, 255): 8, (0, 0, 255): 9}\n",
      "Reading media/Mateus_2022/white\\raw_21008_rf.hdr ...\n",
      "Hypercube shape: (1392, 640, 270)\n",
      "{(0, 0, 0): 0, (128, 255, 128): 1, (128, 255, 255): 2, (128, 128, 255): 3, (128, 255, 0): 4, (255, 255, 128): 5, (255, 128, 0): 6, (192, 128, 255): 7, (255, 128, 255): 8, (0, 0, 255): 9}\n",
      "Reading media/Mateus_2022/white\\raw_9888_rf.hdr ...\n",
      "Hypercube shape: (2000, 640, 270)\n",
      "{(0, 0, 0): 0, (128, 255, 128): 1, (128, 255, 255): 2, (128, 128, 255): 3, (128, 255, 0): 4, (255, 255, 128): 5, (255, 128, 0): 6, (192, 128, 255): 7, (255, 128, 255): 8, (0, 0, 255): 9}\n"
     ]
    }
   ],
   "source": [
    "hc_array_red, max_class_idx, _ = load_hypercubes(plot_hc=False, plot_mask=False, n_max_cubes=inf, folder='media/Mateus_2022/red/')\n",
    "hc_array_white, _, color_dict = load_hypercubes(plot_hc=False, plot_mask=False, n_max_cubes=inf, folder='media/Mateus_2022/white/', baseline_class_idx=max_class_idx)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples per class:\n",
      "Class 0: 12388109\n",
      "Class 1: 144315\n",
      "Class 2: 75078\n",
      "Class 3: 53620\n",
      "Class 4: 71547\n",
      "Class 5: 58680\n",
      "Class 6: 36114\n",
      "Class 7: 35656\n",
      "Class 8: 67157\n",
      "Class 9: 242412\n",
      "Class 10: 98304\n",
      "Class 11: 77229\n",
      "Class 12: 13556\n",
      "Class 13: 105384\n",
      "Class 14: 92432\n",
      "Class 15: 101885\n",
      "Class 16: 261228\n",
      "Class 17: 44654\n",
      "Train size: 145814, Test size: 0\n",
      "Train size: 154362, Test size: 0\n",
      "Train size: 119666, Test size: 0\n",
      "Train size: 110729, Test size: 0\n",
      "Train size: 11596, Test size: 0\n",
      "Train size: 69155, Test size: 0\n",
      "Train size: 168575, Test size: 0\n",
      "Train size: 81132, Test size: 0\n",
      "Train size: 226815, Test size: 0\n",
      "Train size: 89462, Test size: 0\n",
      "Train size: 227458, Test size: 0\n",
      "Train size: 63593, Test size: 0\n",
      "Train size: 110894, Test size: 0\n",
      "|████████████████████████████████████████| 52/52 [100%] in 1:09.4 (0.75/s)                                              ▅▇ 23/52 [44%] in 17s (~21s, 1.4/s) \n"
     ]
    }
   ],
   "source": [
    "hc_set = HypercubeSet(hc_array_red + hc_array_white)\n",
    "hc_set.print_num_samples()\n",
    "hc_set.identify_ground_samples()\n",
    "hc_set.split_hypercubes(test_percentage=.0)\n",
    "transformation, standard_scaler = hc_set.standardize(num_features=config.num_target_features, selection_method=LayerSelectionMethod.FACTOR_ANALYSIS)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading media/Mateus_2021/white\\raw_10208_rf.hdr ...\n",
      "Hypercube shape: (2000, 640, 270)\n",
      "{(0, 0, 0): 0, (128, 255, 128): 1, (128, 255, 255): 2, (128, 128, 255): 3, (128, 255, 0): 4, (255, 255, 128): 5, (255, 128, 0): 6, (192, 128, 255): 7, (255, 128, 255): 8, (0, 0, 255): 9}\n",
      "Reading media/Mateus_2021/white\\raw_12400_rf.hdr ...\n",
      "Hypercube shape: (2000, 640, 270)\n",
      "{(0, 0, 0): 0, (128, 255, 128): 1, (128, 255, 255): 2, (128, 128, 255): 3, (128, 255, 0): 4, (255, 255, 128): 5, (255, 128, 0): 6, (192, 128, 255): 7, (255, 128, 255): 8, (0, 0, 255): 9}\n",
      "Reading media/Mateus_2021/white\\raw_14400_rf.hdr ...\n",
      "Hypercube shape: (2000, 640, 270)\n",
      "{(0, 0, 0): 0, (128, 255, 128): 1, (128, 255, 255): 2, (128, 128, 255): 3, (128, 255, 0): 4, (255, 255, 128): 5, (255, 128, 0): 6, (192, 128, 255): 7, (255, 128, 255): 8, (0, 0, 255): 9}\n",
      "Reading media/Mateus_2021/white\\raw_16592_rf.hdr ...\n",
      "Hypercube shape: (2000, 640, 270)\n",
      "{(0, 0, 0): 0, (128, 255, 128): 1, (128, 255, 255): 2, (128, 128, 255): 3, (128, 255, 0): 4, (255, 255, 128): 5, (255, 128, 0): 6, (192, 128, 255): 7, (255, 128, 255): 8, (0, 0, 255): 9}\n",
      "Reading media/Mateus_2021/white\\raw_18592_rf.hdr ...\n",
      "Hypercube shape: (2000, 640, 270)\n",
      "{(0, 0, 0): 0, (128, 255, 128): 1, (128, 255, 255): 2, (128, 128, 255): 3, (128, 255, 0): 4, (255, 255, 128): 5, (255, 128, 0): 6, (192, 128, 255): 7, (255, 128, 255): 8, (0, 0, 255): 9}\n",
      "Reading media/Mateus_2021/white\\raw_20912_rf.hdr ...\n",
      "Hypercube shape: (2000, 640, 270)\n",
      "{(0, 0, 0): 0, (128, 255, 128): 1, (128, 255, 255): 2, (128, 128, 255): 3, (128, 255, 0): 4, (255, 255, 128): 5, (255, 128, 0): 6, (192, 128, 255): 7, (255, 128, 255): 8, (0, 0, 255): 9}\n",
      "Reading media/Mateus_2021/white\\raw_22912_rf.hdr ...\n",
      "Hypercube shape: (2000, 640, 270)\n",
      "{(0, 0, 0): 0, (128, 255, 128): 1, (128, 255, 255): 2, (128, 128, 255): 3, (128, 255, 0): 4, (255, 255, 128): 5, (255, 128, 0): 6, (192, 128, 255): 7, (255, 128, 255): 8, (0, 0, 255): 9}\n",
      "Reading media/Mateus_2021/white\\raw_4128_rf.hdr ...\n",
      "Hypercube shape: (2000, 640, 270)\n",
      "{(0, 0, 0): 0, (128, 255, 128): 1, (128, 255, 255): 2, (128, 128, 255): 3, (128, 255, 0): 4, (255, 255, 128): 5, (255, 128, 0): 6, (192, 128, 255): 7, (255, 128, 255): 8, (0, 0, 255): 9}\n",
      "Reading media/Mateus_2021/white\\raw_6128_rf.hdr ...\n",
      "Hypercube shape: (2000, 640, 270)\n",
      "{(0, 0, 0): 0, (128, 255, 128): 1, (128, 255, 255): 2, (128, 128, 255): 3, (128, 255, 0): 4, (255, 255, 128): 5, (255, 128, 0): 6, (192, 128, 255): 7, (255, 128, 255): 8, (0, 0, 255): 9}\n",
      "Reading media/Mateus_2021/white\\raw_8208_rf.hdr ...\n",
      "Hypercube shape: (2000, 640, 270)\n",
      "{(0, 0, 0): 0, (128, 255, 128): 1, (128, 255, 255): 2, (128, 128, 255): 3, (128, 255, 0): 4, (255, 255, 128): 5, (255, 128, 0): 6, (192, 128, 255): 7, (255, 128, 255): 8, (0, 0, 255): 9}\n"
     ]
    }
   ],
   "source": [
    "hc_array_white_2021, _, _ = load_hypercubes(plot_hc=False, plot_mask=False, n_max_cubes=inf, folder='media/Mateus_2021/white/', color_dict=color_dict, baseline_class_idx=max_class_idx)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples per class:\n",
      "Class 0: 10953299\n",
      "Class 1: 0\n",
      "Class 2: 0\n",
      "Class 3: 0\n",
      "Class 4: 0\n",
      "Class 5: 0\n",
      "Class 6: 0\n",
      "Class 7: 0\n",
      "Class 8: 0\n",
      "Class 9: 412297\n",
      "Class 10: 136221\n",
      "Class 11: 111267\n",
      "Class 12: 139110\n",
      "Class 13: 166665\n",
      "Class 14: 133336\n",
      "Class 15: 91418\n",
      "Class 16: 223278\n",
      "Class 17: 433109\n"
     ]
    }
   ],
   "source": [
    "hc_set = HypercubeSet(hc_array_white_2021)\n",
    "hc_set.print_num_samples()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 264828, Test size: 0\n",
      "Train size: 245153, Test size: 0\n",
      "Train size: 245510, Test size: 0\n",
      "Train size: 248290, Test size: 0\n",
      "Train size: 246433, Test size: 0\n",
      "Train size: 123439, Test size: 0\n",
      "Train size: 174447, Test size: 0\n",
      "Train size: 78047, Test size: 0\n",
      "Train size: 53095, Test size: 0\n",
      "Train size: 167459, Test size: 0\n",
      "|████████████████████████████████████████| 40/40 [100%] in 43.5s (0.92/s)                                                ▄▆█ 32/40 [80%] in 24s (~6s, 1.3/s)  ▃▁▃ 33/40 [82%] in 26s (~6s, 1.3/s) \n"
     ]
    },
    {
     "data": {
      "text/plain": "(FactorAnalysis(n_components=40, random_state=42), StandardScaler())"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hc_set.identify_ground_samples()\n",
    "hc_set.split_hypercubes(test_percentage=.0)\n",
    "hc_set.standardize(num_features=config.num_target_features, selection_method=LayerSelectionMethod.FACTOR_ANALYSIS, standard_scaler=standard_scaler, transformation=transformation)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "network_type = 'allopezr_2d'\n",
    "read_json_config(paths.config_file, network_type=network_type)\n",
    "network_name = get_name(network_type)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights file results/uav/network\\allopezr_2d_23x22_16_window_size_test_0.h5\n",
      "Model: \"model_9\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_10 (InputLayer)          [(None, 23, 23, 40)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " reshape_18 (Reshape)           (None, 529, 40)      0           ['input_10[0][0]']               \n",
      "                                                                                                  \n",
      " lambda_9 (Lambda)              (None, 529, 40)      0           ['reshape_18[0][0]']             \n",
      "                                                                                                  \n",
      " spatial_attention_9 (SpatialAt  (None, 529, 40)     1058        ['lambda_9[0][0]']               \n",
      " tention)                                                                                         \n",
      "                                                                                                  \n",
      " reshape_19 (Reshape)           (None, 23, 23, 40)   0           ['spatial_attention_9[0][0]']    \n",
      "                                                                                                  \n",
      " concatenate_27 (Concatenate)   (None, 23, 23, 80)   0           ['input_10[0][0]',               \n",
      "                                                                  'reshape_19[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_90 (Conv2D)             (None, 23, 23, 32)   2592        ['concatenate_27[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_92 (Conv2D)             (None, 23, 23, 32)   2592        ['concatenate_27[0][0]']         \n",
      "                                                                                                  \n",
      " max_pooling2d_18 (MaxPooling2D  (None, 12, 12, 80)  0           ['concatenate_27[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_91 (Conv2D)             (None, 12, 12, 32)   9248        ['conv2d_90[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_93 (Conv2D)             (None, 12, 12, 32)   25632       ['conv2d_92[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_94 (Conv2D)             (None, 12, 12, 32)   2592        ['max_pooling2d_18[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate_28 (Concatenate)   (None, 12, 12, 96)   0           ['conv2d_91[0][0]',              \n",
      "                                                                  'conv2d_93[0][0]',              \n",
      "                                                                  'conv2d_94[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, 12, 12, 96)  384         ['concatenate_28[0][0]']         \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " leaky_re_lu_18 (LeakyReLU)     (None, 12, 12, 96)   0           ['batch_normalization_18[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_18 (Dropout)           (None, 12, 12, 96)   0           ['leaky_re_lu_18[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_95 (Conv2D)             (None, 12, 12, 96)   9312        ['dropout_18[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_97 (Conv2D)             (None, 12, 12, 96)   9312        ['dropout_18[0][0]']             \n",
      "                                                                                                  \n",
      " max_pooling2d_19 (MaxPooling2D  (None, 6, 6, 96)    0           ['dropout_18[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_96 (Conv2D)             (None, 6, 6, 96)     83040       ['conv2d_95[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_98 (Conv2D)             (None, 6, 6, 96)     230496      ['conv2d_97[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_99 (Conv2D)             (None, 6, 6, 96)     9312        ['max_pooling2d_19[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate_29 (Concatenate)   (None, 6, 6, 288)    0           ['conv2d_96[0][0]',              \n",
      "                                                                  'conv2d_98[0][0]',              \n",
      "                                                                  'conv2d_99[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_19 (BatchN  (None, 6, 6, 288)   1152        ['concatenate_29[0][0]']         \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " leaky_re_lu_19 (LeakyReLU)     (None, 6, 6, 288)    0           ['batch_normalization_19[0][0]'] \n",
      "                                                                                                  \n",
      " flatten_9 (Flatten)            (None, 10368)        0           ['leaky_re_lu_19[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_19 (Dropout)           (None, 10368)        0           ['flatten_9[0][0]']              \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 17)           176273      ['dropout_19[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 562,995\n",
      "Trainable params: 562,227\n",
      "Non-trainable params: 768\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import papers\n",
    "\n",
    "# Read network weights\n",
    "network_weights_file = os.path.join(paths.result_folder + 'network/', network_name + \"*.h5\")\n",
    "network_weights_files = glob.glob(network_weights_file)\n",
    "if len(network_weights_files) > 0:\n",
    "    network_weights_file = network_weights_files[-1]\n",
    "    print(\"Loading weights file \" + network_weights_file)\n",
    "    model = keras.models.load_model(network_weights_file,\n",
    "                                    custom_objects={'SpatialAttention': papers.aspn.SpatialAttention,\n",
    "                                                    'SecondOrderPooling': papers.aspn.SecondOrderPooling})\n",
    "\n",
    "    model.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "num_classes = hc_set.get_num_classes() - 1\n",
    "img_shape = (config.patch_size, config.patch_size, config.num_target_features)\n",
    "num_iterations = config.num_training_splits * 20\n",
    "percentage_step = 1.0 / num_iterations"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "305/305 [==============================] - 5s 8ms/step\n",
      "305/305 [==============================] - 3s 9ms/step - loss: 155.3234 - sparse_categorical_accuracy: 0.0700\n",
      "Test Loss: 155.32342529296875, Test Accuracy: 0.07002973556518555\n",
      "306/306 [==============================] - 2s 7ms/step\n",
      "306/306 [==============================] - 3s 9ms/step - loss: 156.5564 - sparse_categorical_accuracy: 0.0625\n",
      "Test Loss: 156.55642700195312, Test Accuracy: 0.062480825930833817\n",
      "306/306 [==============================] - 2s 7ms/step\n",
      "306/306 [==============================] - 3s 9ms/step - loss: 154.6658 - sparse_categorical_accuracy: 0.0682\n",
      "Test Loss: 154.665771484375, Test Accuracy: 0.06816785782575607\n",
      "305/305 [==============================] - 2s 7ms/step\n",
      "305/305 [==============================] - 3s 9ms/step - loss: 156.2232 - sparse_categorical_accuracy: 0.0680\n",
      "Test Loss: 156.2231903076172, Test Accuracy: 0.06798605620861053\n",
      "306/306 [==============================] - 2s 7ms/step\n",
      "306/306 [==============================] - 3s 9ms/step - loss: 155.4495 - sparse_categorical_accuracy: 0.0626\n",
      "Test Loss: 155.44949340820312, Test Accuracy: 0.06262151151895523\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Number of classes in y_true not equal to the number of columns in 'y_score'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [11], line 33\u001B[0m\n\u001B[0;32m     30\u001B[0m test_prediction_prob_global \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39masarray(test_prediction_prob_global)\n\u001B[0;32m     32\u001B[0m metrics \u001B[38;5;241m=\u001B[39m training_metrics\u001B[38;5;241m.\u001B[39mTrainingMetrics()\n\u001B[1;32m---> 33\u001B[0m \u001B[43mmetrics\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mappend_evaluation\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_test_global\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_prediction_global\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_prediction_prob_global\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     34\u001B[0m metrics\u001B[38;5;241m.\u001B[39mprint_metrics()\n\u001B[0;32m     36\u001B[0m \u001B[38;5;66;03m# Graphic results\u001B[39;00m\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\VineyardUAVClassification\\training_metrics.py:21\u001B[0m, in \u001B[0;36mTrainingMetrics.append_evaluation\u001B[1;34m(self, y_true, y_pred, y_pred_prob)\u001B[0m\n\u001B[0;32m     19\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_test_kappa\u001B[38;5;241m.\u001B[39mappend(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__get_kappa_loss(y_pred, y_true))\n\u001B[0;32m     20\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_test_f1\u001B[38;5;241m.\u001B[39mappend(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__get_f1_score(y_true, y_pred))\n\u001B[1;32m---> 21\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_test_roc_auc\u001B[38;5;241m.\u001B[39mappend(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__get_roc_auc_score\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_true\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_pred_prob\u001B[49m\u001B[43m)\u001B[49m)\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\VineyardUAVClassification\\training_metrics.py:99\u001B[0m, in \u001B[0;36mTrainingMetrics.__get_roc_auc_score\u001B[1;34m(y_true, y_pred)\u001B[0m\n\u001B[0;32m     97\u001B[0m \u001B[38;5;129m@staticmethod\u001B[39m\n\u001B[0;32m     98\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__get_roc_auc_score\u001B[39m(y_true, y_pred):\n\u001B[1;32m---> 99\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mroc_auc_score\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_true\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maverage\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mweighted\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmulti_class\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43movr\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\VineyardUAVClassification\\venv\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:565\u001B[0m, in \u001B[0;36mroc_auc_score\u001B[1;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001B[0m\n\u001B[0;32m    563\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m multi_class \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mraise\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m    564\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmulti_class must be in (\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124movo\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124movr\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m)\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m--> 565\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_multiclass_roc_auc_score\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    566\u001B[0m \u001B[43m        \u001B[49m\u001B[43my_true\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_score\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmulti_class\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maverage\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msample_weight\u001B[49m\n\u001B[0;32m    567\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    568\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m y_type \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbinary\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m    569\u001B[0m     labels \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39munique(y_true)\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\VineyardUAVClassification\\venv\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:674\u001B[0m, in \u001B[0;36m_multiclass_roc_auc_score\u001B[1;34m(y_true, y_score, labels, multi_class, average, sample_weight)\u001B[0m\n\u001B[0;32m    672\u001B[0m     classes \u001B[38;5;241m=\u001B[39m _unique(y_true)\n\u001B[0;32m    673\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(classes) \u001B[38;5;241m!=\u001B[39m y_score\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m]:\n\u001B[1;32m--> 674\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    675\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNumber of classes in y_true not equal to the number of \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    676\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcolumns in \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124my_score\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    677\u001B[0m         )\n\u001B[0;32m    679\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m multi_class \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124movo\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m    680\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m sample_weight \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;31mValueError\u001B[0m: Number of classes in y_true not equal to the number of columns in 'y_score'"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import training_metrics\n",
    "\n",
    "#### Split test into batches\n",
    "y_test_global = []\n",
    "test_prediction_global = []\n",
    "test_prediction_prob_global = []\n",
    "\n",
    "for batch in range(config.num_test_splits):\n",
    "    X_test, y_test = hc_set.split(patch_size=config.patch_size, patch_overlap=config.patch_overlapping,\n",
    "                                  train=True, start_percentage=percentage_step * batch,\n",
    "                                  end_percentage=percentage_step * (batch + 1))\n",
    "\n",
    "    test_prediction_prob = model.predict(X_test)\n",
    "    test_prediction = np.argmax(test_prediction_prob, axis=1)\n",
    "\n",
    "    test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "    print(\"Test Loss: \" + str(test_loss) + \", Test Accuracy: \" + str(test_accuracy))\n",
    "\n",
    "    # y test to int\n",
    "    y_test_global.extend(np.asarray(y_test, dtype=\"int64\").tolist())\n",
    "    test_prediction_global.extend(test_prediction.tolist())\n",
    "    test_prediction_prob_global.extend(test_prediction_prob.tolist())\n",
    "\n",
    "    del X_test, y_test, test_prediction, test_prediction_prob\n",
    "    gc.collect()\n",
    "\n",
    "y_test_global = np.asarray(y_test_global)\n",
    "test_prediction_global = np.asarray(test_prediction_global)\n",
    "test_prediction_prob_global = np.asarray(test_prediction_prob_global)\n",
    "\n",
    "metrics = training_metrics.TrainingMetrics()\n",
    "metrics.append_evaluation(y_test_global, test_prediction_global, test_prediction_prob_global)\n",
    "metrics.print_metrics()\n",
    "\n",
    "# Graphic results\n",
    "render_confusion_matrix(y_test_global, test_prediction_global, model_name=network_name)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
